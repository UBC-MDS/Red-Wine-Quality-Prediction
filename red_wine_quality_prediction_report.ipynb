{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Wine Quality Prediction \n",
    "\n",
    "authors: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/winequality-red.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_na = df.isna().any().any()\n",
    "has_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['quality'])\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 522)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = {\n",
    "    \"dummy\": DummyClassifier(random_state=522), \n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(random_state=123), \n",
    "    'Ridge model':Ridge(),\n",
    "    'linear SVC':SVC(kernel = 'linear'),\n",
    "    'decision tree': DecisionTreeClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "results1 = []\n",
    "\n",
    "for name, model in models1.items():\n",
    "    pipeline =  make_pipeline(StandardScaler(), model) \n",
    "    scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    " #   mean_std_cross_val_scores\n",
    "    results1.append({\n",
    "        'model': name,\n",
    "        'test_score': np.mean(scores['test_score']),\n",
    "        'train_score': np.mean(scores['train_score']),\n",
    "        'fit_time': np.mean(scores['fit_time']),\n",
    "        'score_time': np.mean(scores['score_time'])\n",
    "    })\n",
    "\n",
    "results_df1 = pd.DataFrame(results1)\n",
    "results_df1.set_index('model', inplace=True)\n",
    "results_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(StandardScaler(), Ridge())\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "\n",
    "coeffs = pipe_ridge.named_steps[\"ridge\"].coef_\n",
    "\n",
    "# Use df.columns to get the feature names if X_train was derived from df\n",
    "coeff_df = pd.DataFrame(data=coeffs, index=X_train.columns, columns=[\"Coefficients\"])\n",
    "sorted_coeff_df = coeff_df.sort_values(by=\"Coefficients\", ascending=False)\n",
    "\n",
    "sorted_coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop variables with small coefficients(< 0.05) (free sulfur dioxide, residual sugar, density, citric acid)\n",
    "X = df.drop(columns = ['quality','free sulfur dioxide', 'residual sugar', 'density', 'citric acid'])\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 522)\n",
    "results1 = []\n",
    "\n",
    "for name, model in models1.items():\n",
    "    pipeline =  make_pipeline(StandardScaler(), model) \n",
    "    scores = cross_validate(pipeline, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    " #   mean_std_cross_val_scores\n",
    "    results1.append({\n",
    "        'model': name,\n",
    "        'test_score': np.mean(scores['test_score']),\n",
    "        'train_score': np.mean(scores['train_score']),\n",
    "        'fit_time': np.mean(scores['fit_time']),\n",
    "        'score_time': np.mean(scores['score_time'])\n",
    "    })\n",
    "\n",
    "results_df1 = pd.DataFrame(results1)\n",
    "results_df1.set_index('model', inplace=True)\n",
    "results_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge coefficient\n",
    "pipe_ridge = make_pipeline(StandardScaler(), Ridge())\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "\n",
    "coeffs = pipe_ridge.named_steps[\"ridge\"].coef_\n",
    "\n",
    "# Use df.columns to get the feature names if X_train was derived from df\n",
    "coeff_df = pd.DataFrame(data=coeffs, index=X_train.columns, columns=[\"Coefficients\"])\n",
    "sorted_coeff_df = coeff_df.sort_values(by=\"Coefficients\", ascending=False)\n",
    "\n",
    "sorted_coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS:\n",
    "\n",
    "In this study, we employed various machine learning models to predict the quality of wine based on its chemical properties. The models used included a Dummy model, K-Nearest Neighbors (KNN), Support Vector Machine (SVM) with Radial Basis Function (RBF) kernel, Ridge Regression, and Linear Support Vector Classification (SVC). These models were rigorously cross-validated with 5 folds to assess their performance. The Python programming language, along with essential packages such as Pandas,scikit-learn was instrumental in conducting this analysis.\n",
    "\n",
    "The initial performance of each model, as measured by test scores, was as follows:\n",
    "\n",
    "Dummy Model: 0.437059\n",
    "KNN: 0.562917\n",
    "RBF SVM: 0.615313\n",
    "Ridge Model: 0.340925\n",
    "Linear SVC: 0.566094\n",
    "\n",
    "To improve model performance and streamline the feature set, we conducted a coefficient analysis. This analysis led to the exclusion of variables with coefficients less than 0.05, including variables within 'free sulfur dioxide', 'residual sugar', 'density', and 'citric acid'. The updated model performances were:\n",
    "\n",
    "Dummy Model: 0.437059 (unchanged)\n",
    "KNN: 0.571541\n",
    "RBF SVM: 0.606740\n",
    "Ridge Model: 0.344543\n",
    "Linear SVC: 0.576244\n",
    "\n",
    "The new coefficients for the remaining variables were:\n",
    "\n",
    "Alcohol: 0.322230\n",
    "Sulphates: 0.145794\n",
    "Fixed Acidity: 0.011367\n",
    "pH: -0.059857\n",
    "Chlorides: -0.067214\n",
    "Total Sulfur Dioxide: -0.089573\n",
    "Volatile Acidity: -0.179928\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This refined analysis suggests a more focused model, with the reduced feature set enhancing the predictive accuracy of certain models, notably the KNN and Linear SVC. The data utilized for this study encompass various physicochemical properties of wine, such as acidity, sulfur dioxide levels, and alcohol content, which are believed to influence its quality.\n",
    "Based on the results, we will focus on decision tree model, RBF SVM, Ridge for hyperparameter optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
